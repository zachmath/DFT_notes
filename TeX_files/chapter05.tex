\chapter{Nuclear Shape Deformations}

Rick Casten has given several lectures about nuclear shape deformations and other such things. A lot of this will probably just be restating things he has said in my own words.

First of all, one important tool that you should understand in order to talk about nuclear shape deformations is a Nilsson diagram. First of all, you've seen level diagrams in atomic and nuclear spectroscopy. Figure \ref{fig:NuclearShells}, for instance, is a familiar illustration of low-lying energy levels for a harmonic oscillator potential, both before and after adding a spin-orbit interaction term which leads to the well-known nuclear "magic numbers."

\begin{wrapfigure}{R}{0.5\textwidth}
%\centering
\includegraphics[width=0.45\textwidth]{TeX_files/NuclearShells}
\caption[Nuclear Shell Model level diagram]{From Wikipedia: "Low-lying energy levels in a single-particle shell model with an oscillator potential (with a small negative l2 term) without spin-orbit (left) and with spin-orbit (right) interaction. The number to the right of a level indicates its degeneracy, (2j+1). The boxed integers indicate the magic numbers."}
\label{fig:NuclearShells}
\end{wrapfigure}

Now imagine you stretch out the nucleus somehow. That'll certainly change the spacing and position of the energy levels, because some electron orbitals have a sort of intrinsic shape characteristic that might be better- or worse-suited for the new elongation.

Finally, imagine that you do the stretching \textit{continuously}. That is what is done in a Nilsson diagram. For example, in figure \ref{fig:NilssonDiagram}, the system is elongated from a spherical ground state, and the changing energy levels are the curves, which frequently end up crossing one another. An important thing to notice is that, for different deformations you might have different shell gaps, and as well you might find that different orbitals are more favorable at different deformations.

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{TeX_files/NilssonDiagram}
\caption[Nilsson Diagram for Zr-105]{Nilsson Diagram for Zr-105, plotted against elongation parameter $\epsilon_2$}
\label{fig:NilssonDiagram}
\end{figure}

Anyway, that's all helpful \textit{once you know} the deformation. And there's a lot of useful and interesting things you can say and predict using a Nilsson diagram - heck, if you know the shape you can [qualitatively] even \textit{draw} a Nilsson diagram, just by thinking about the physical system and how the orbitals are probably behaving.  BUT if you want to understand why a nucleus deforms in the first place, that's a whole other story.

\section{What causes nuclear ground state deformations?}

As with most peculiarities of nuclear structure, the source of nuclear deformation is primarily an artifact of shell structure. In particular, when there is a large shell gap, the nucleus will get sort of "locked" into a particular stable configuration, and if that happens to be a deformed configuration because of the orbital characteristics of the outermost nucleons (because that's the only thing that could matter, right?), then so be it.

A question that I have is how is there ground state deformation in even-even nuclei? Because even-even nuclei all have, without exception, spin-parity $0^+$, and yet $^{152}Dy$ (for example) is highly-deformed. Am I misunderstanding the implications of such a spin-parity assignment? Or am I misunderstanding what is meant by "ground state deformed"?

I don't think this is a real answer, but one way to identify even-even deformed nuclei is to look for nuclei with a large $\frac{E(4^+)}{E(2^+)}$ ratio (or a related method is to look for those with a relatively-small $E(2^+)$).

\section{Phenomenology of Nilsson Diagrams}

[Basically here is where you were thinking about Casten's slides. He goes through and talks about whether a level's energy will go up or down, and how it will curve, just by thinking about the orbital motion of single particles around different axes of the deformed system.]

\section{What causes nuclear ground state deformations? Part 2}
\subsection{What causes fission?}

I think there's a couple of effects at play that lead to fission. First of all, what gets the nucleus moving in the first place, and second, what \textit{keeps} it moving?

To answer the first question, imagine you were to buy a bunch of nucleons at the store and then put them in a box together. Just dump them in with some arbitrary configuration. They'll start to attract and repel one another and there will be kind of a chaotic mess of particle motions to keep track of. TDHF will kind of give you a sense of what's going on in sort of an average sense.

Eventually, the system might settle into a set of sort of normal modes. There will probably be several overlapping normal modes happening at once, so the motion will still look pretty chaotic, but in some average sense you might get something that starts to move with some pseudo-regularity. And with time (I suppose regardless of whether the system motion os regular or not), the system might (for example) elongate, and in fact it might elongate enough for there to be a level crossing in the Nilsson diagram.

When this happens, the system has some deciding to do. It might continue on its current trajectory, or it might jump onto another trajectory (that is, there might be a nucleonic transition from one energy level to another). I suppose it is pretty difficult in practice for a nucleon to make these transitions, because you have all kind of things like conservation of angular momentum and Pauli's principle and such to consider. BUT if you transition a pair of nucleons instead of just one, you can skirt around a lot of these issues, and so I think that's what frequently tends to happen. That is why pairing correlations are sometimes called the "lubricant" of nuclear fission \cite{Bulgac2016}.

To go further brings you into the world of diabatic vs adiabatic level crossings. Witek talks about this in \cite{Nazarewicz1993} (and that's what I'm trying to read through and understand right now). First, some terminology: The words ``diabatic" and ``adiabatic" come from Greek: ``a"= ``not", ``dia"=``through", ``batok"=``passable." So at a diabatic level crossing, the levels just pass right through one another without interacting or acknowledging one another. At an adiabatic level crossing, there might be some kind of level mixing as a result of residual interactions (basically, your single-particle picture wasn't good enough, I suppose). This is the point being illustrated in figure 1 of that reference: In the diabatic picture, you have two independent harmonic oscillators that happen to occupy the same space, whereas in the adiabatic picture, you have just a couple of messy, non-symmetric potential wells.

\section{Between barrier and scission}

I was asked a question during my second committee meeting by Filomena that is worth reflecting on: why can we use Langevin dynamics (which I believe is a semiclassical construction) to describe the pathway from barrier to scission? And I think the answer lies in the adiabatic approximation, that collective motion is slow compared to single particle motion. That said, it merits some additional thought, perhaps once I get around to programming it.

I was talking with Samuel the other day, and we're trying to figure out a better way to predict the fragments that doesn't involve the large, multidimensional PES we've got for cases like plutonium and oganesson. The current framework for that requires you to have the action at each point along the outer turning line, and then the shape of the PES from the outer turning line to scission. We are lucky because 2-dimensions seems to be sufficient for describing the fragment distributions fairly well ($Q_{20}$ and $Q_{30}$). But still, is there a better way?

No matter what, we'll probably need the barrier in order to find the action. Unless you can think of another way to compute the action as a function of where it leaves the barrier. So then instead you might try to find ways to avoid computing the PES way out there, instead. The approach used now is Langevin, which is really pretty much a classical description. Additionally, Andre Michaudon's review in \textit{Advances in Nuclear Physics Volume 6} suggests that properties near the ground state are dominated by shell effects, while structure properties for highly-deformed systems are mostly ``washed-out by residual interactions'' (there, they say, the LDM actually does a pretty good job).

What I'm wondering is the following: That highly-deformed case is pretty complicated because you don't quite have a single hydrogen-like ``central mean-field'' (like you would near the ground state) and you don't quite have two of them, either (like you would post-scission). Instead you have some messy in-between thing, with crazy mixed-up orbitals, and really since there is no central force, you just have a jumbled bunch of loose particles gettin' in each others' fields and no\footnote{Clearly there must be some order, because the fragments that leave are clearly correlated with the shape of the parent} clear order, flowing back and forth until the clusters move too far away from one another and you're left with whatever's left. So your best bet to model that is probably some kind of statistical model. That's why Langevin is used; you need something basically with a temperature dependence.

A question worth asking is: are thermal fluctuations all you need there? Or do you need to include quantum fluctuations somehow as well? Because I don't know if Langevin handles both. And my other [related] question is: does the shape of the PES really matter after that? Does it somehow still include whatever effects of shell structure are important there? Or were those only important to get you through the barrier, and now thermal physics will carry you to scission along whatever trajectory they were already on, and all the important shell information is already baked in? I'm guessing you still need some type of shell structure to guide you, or somehow to build that quantum information into your dispersion. So the way it works now is that quantum mechanics builds the playground for you, and then you let thermal physics play around and do whatever it wants, but the rules are it has to play on the ground you built for it.

What if you just built your quantum mechanical interaction into the Langevin equations as an additional force term? Like including a Skyrme term in there or something? Would that preserve all the information you need? Or maybe there's another, similar framework to work in? Or perhaps there's another framework that allows you to handle the fluctuations after the barrier. By then, I feel like you've done sort of the hard part - I mean, there's two hard parts: the 1st half, and the 2nd half, but you get what I mean. By then, I should say, you've tunneled through the barrier. You've taken the system from a point where it is primarily quantum mechanical and brought it to a point where it is primarily thermal, and now it has to go back from thermal to quantum mechanical. To put it another way, you took it from one starting point to a lot of midpoints, and now you have to take it from a lot of midpoints to a relatively small number(?) of end points. I wonder if, at this point, you'd be able to hijack any of the Hauser-Feschbach work that has been done.

Another, totally unrelated question that might be worth addressing is: Does triaxiality ever play a role near scission?

\section{Describing Scission}

(This is probably way out of place, but whatever...) Intuitively, you might think that the driving factor which determines fragment ID distributions would be shell structure of the fragments. And if I'm reading this right \cite[2nd paragraph + references]{Mcdonnell2014}, you'd be partly right: the \textit{real} driving factor is shell structure of the \textit{prefragments}, and an important factor in understanding this is that the prefragments are typically highly-deformed, which means that their shell structure is probably totally different than it would be for those same fragments in their ground state.

\section{Multipole moments}
Something I have said in the past is that the multipole moments of a system are essentially related to the spherical harmonics expansion. That's true-ish, but I should do this a little bit more carefully.

Imagine you have a single particle, and origin, and a coordinate system. Furthermore, suppose for the sake of argument that the origin does not coincide with the location of the particle. Automatically, then, the system has some dipole moment. This moment is a geometrical attribute of the system. It contains information about the charge of the system and the way it is distributed. The sum of multipole moments gives the total potential.

But in fact you might go further, for if the particle is not aligned with a coordinate axis, then you introduce higher-order multipole moments, as well. In general it will have a monopole contribution, a dipole contribution, a quadrupole contribution, etc. Griffiths E\&M p. 147-148 shows how this can be done systematically, as does Jackson p. 145. When you draw out a system involving an origin, a source point, and an observation point, and you describe the relation between them using some law of cosines stuff, and expand out in terms of $\frac{r'}{r}$, where $r'$ is the distance from origin to source point and $r$ the vector separating origin and observation points, then you end up getting Legendre polynomials. That is given for a single source point in Griffiths (3.94), and then you can sum over all source points as seen in Griffiths (3.95). Jackson uses an expansion in spherical harmonics $Y^m_l$ instead of Legendre polynomials $P_l$, which I supposed contains fundamentally the same information but going back and forth takes some work (see Jackson (4.2)). The multipole moment is defined explicitly and plainly in Jackson in terms of spherical harmonics. It is the part that contains strictly the information about the source, and which is independent of the observation point:

\begin{align*}
\Phi(\vec{x}) &= \frac{1}{4\pi\epsilon_0}\int\frac{\rho(\vec{x'})}{|\vec{x}-\vec{x'}|}d^3x' \\
&= \frac{1}{\epsilon_0}\sum_{l,m}\frac{1}{2l+1}\left[\int Y_l^{*m}(\theta',\phi')r'^l\rho(\vec{x'})d^3x'\right]\frac{Y_l^m(\theta,\phi)}{r^{l+1}} \\
&\equiv \frac{1}{\epsilon_0}\sum_{l,m}\frac{1}{2l+1}q_{lm}\frac{Y_l^m(\theta,\phi)}{r^{l+1}}
\end{align*}

\noindent I'm not quite sure what the ``charge'' is in the multipole decomposition of the nuclear shape, but maybe it's the number of nucleons? Or even just 1? I just base that on the fact that the total monopole moment for protons equals the number of protons (so if you compute the monopole moment for each particle individually, I don't know what they will be individually, but together they'll add up to the total number of protons). Actually, as I think about it, it's probably just the mean field density. That's the main thing we're using/looking for, after all. Duh.

So the main thing you need to get out of this (regardless of how we got there; multipole moments are standard now) is that multipole moments are defined in the following way:

\begin{equation*}
q_{lm} = \int Y_l^{*m}(\theta',\phi')r'^l\rho(\vec{x'})d^3x'
\end{equation*}

As far as HFB is concerned, your multipole constraint appears with a Lagrange multiplier: $\hat{H} - \lambda\hat{N} - \lambda_i \hat{Q}_i$. The $\hat{Q}$ is the multipole operator. What is it operating on? The density. I don't know if that coefficient has any physical significance.

On a related note, sometimes nuclear deformations are described in terms of the coordinates $(\beta_{20}, \gamma)$ instead of $(Q_{20},Q_{22})$. There's some kind of relation between $\beta_2$ and $Q_{20}$, and I'm not positive what it is but \cite{Giuliani2017} has an equation

\begin{equation*}
\beta_{20} = \frac{\sqrt{20\pi}}{5A}\frac{Q_{20}}{r^2}
\end{equation*}

\noindent where $r=1.2A^\frac{1}{3}$ fm. I don't know if that's generally true but I'ma hold onto it for a while and see if anything else comes up.

In fact, a slightly more general definition (which I found in \cite{Afanasjev2018}) is the following:

\begin{align*}
Q_{20} &= \int d^3r\rho(r) (2z^2 - x^2 - y^2) \\
Q_{22} &= \int d^3r\rho(r) (x^2 - y^2) \\
\beta_2 &= \sqrt{\frac{5}{16\pi}}\frac{4\pi}{3AR_0^2}\sqrt{Q_{20}^2 + Q_{22}^2} \\
\gamma &= \arctan \sqrt{2}\frac{Q_{22}}{Q_{20}}
\end{align*}

\noindent where again $R_0=1.2A^\frac{1}{3}$ fm.

A question you might consider asking at some point is whether there are reasonable conditions under which seemingly-pedantic cases where, for instance, $Q_{22}=0$ but triaxiality is intact, might occur.